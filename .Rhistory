summary(numericvars)
numericvars <- NULL
numericvarsid <- NULL
non_numericvars <- NULL
non_numericvarsid <- NULL
id<-0L
for (Var in names(nzv_training)) {
id<-id+1
if(class(nzv_training[,Var]) == 'integer' | class(nzv_training[,Var]) == 'numeric') {
numericvars <- c(numericvars,Var)
numericvarsid <- c(numericvarsid,id)
}
else {
non_numericvars <- c(non_numericvars,Var)
non_numericvarsid <- c(non_numericvarsid,id)
}
}
library(lattice)
library(ggplot2)
library(graphics)
library(Hmisc)
library(e1071)
library(caret)
training = read.csv("pml-training.csv")
testing =  read.csv("pml-testing.csv")
nzv <- nearZeroVar(training[,-160])
dim(training)
nzv_training <- training[,-nzv]
dim(nzv_training)
preProcess(nzv_training[,-160], method="pca", thresh=0.8)
numericvars <- NULL
numericvarsid <- NULL
non_numericvars <- NULL
non_numericvarsid <- NULL
id<-0L
for (Var in names(nzv_training)) {
id<-id+1
if(class(nzv_training[,Var]) == 'integer' | class(nzv_training[,Var]) == 'numeric') {
numericvars <- c(numericvars,Var)
numericvarsid <- c(numericvarsid,id)
}
else {
non_numericvars <- c(non_numericvars,Var)
non_numericvarsid <- c(non_numericvarsid,id)
}
}
summary(numericvars)
numericvarsid
numPCATrain-<preProcess(data=nzv_training[,numericvarsid],method="pca",thresh=0.9)
numPCATrain<-preProcess(data=nzv_training[,numericvarsid],method="pca",thresh=0.9)
numPCATrain<-preProcess(nzv_training$classe,data=nzv_training[,numericvarsid],method="pca",thresh=0.9)
numPCATrain<-preProcess(nzv_training[,numericvarsid],method="pca",thresh=0.9)
numPCATrain
numPCATrain<-preProcess(nzv_training[,numericvarsid],method="pca",thresh=0.8)
numPCATrain
preProcTrain<-cbind(numPCATrain,numPCATrain[,non_numericvarsid])
call(numPCATrain)
rotation(numPCATrain)
preProcTrain<-cbind(numPCATrain,numPCATrain[,non_numericvarsid],na.remove = TRUE)
numPCATrain<-preProcess(nzv_training[,numericvarsid],method="pca",thresh=0.8)
numPCATrain<-preProcess(nzv_training[,numericvarsid],method="pca",thresh=0.8,na.remove = TRUE)
numPCATrain
m<-abs(cor(nzv_training[,numericvarsid]))
diag(m)<-0
which(m>0.75,arr.ind=T)
optimTraining<-cbind(numPCATrain$x,nzv_training[,-numericvarsid])
head(numPCATrain$x)
head(numPCATrain$x[,1:17])
numPCATrain
numPCATrain$x
numPCATrain<-prcomp(nzv_training[,numericvarsid])
?prcomp
numPCATrain<-prcomp(nzv_training[,numericvarsid],center=TRUE,scale=TRUE,newdata="new_pcaTrainNumeric")
numPCATrain<-prcomp(nzv_training[,numericvarsid])
numPCATrain<-preProcess(nzv_training[,numericvarsid],method="pca",thresh=0.80,na.remove = TRUE)
numPCATrain<-preProcess(nzv_training[,numericvarsid],method="pca",thresh=0.80,na.remove = TRUE,newdata="newdata")
head(newdata)
summary(newdata)
numPCATrain
?preProcess
numPCATrain$dim
numPCATrain$dim$call
numPCATrain$call
numPCATrain$rotation
head(numPCATrain$x[,1:3])
head(numPCATrain$x)
numPCATrain$x
?preProcess
numericTraining<-predict(numPCATrain,nzv_training[,numericvarsid])
head(numericTraining)
head(nzv_training[,numericvarsid])
df[,colSums(is.na(df)) != nrow(df)]
numericTraining<-nzv_training[,numericvarsid])
numericTraining<-nzv_training[,numericvarsid]
summary(numericTraining[,colSums(is.na(df)) != nrow(df)])
summary(numericTraining[,colSums(is.na(numericTraining)) != nrow(numericTraining)])
numericNANTraining<-numericTraining[,colSums(is.na(numericTraining)) != nrow(numericTraining)])
numericNANTraining<-numericTraining[,colSums(is.na(numericTraining)) != nrow(numericTraining)]
dim(numericNANTraining)
numericNANTraining<-numericTraining[,colSums(is.na(numericTraining)) >= 0.4*nrow(numericTraining)]
dim(numericNANTraining)
m<-abs(cor(numericNANTraining))
diag(m)<-0
which(m>0.75,arr.ind=T)
m<-abs(cor(numericNANTraining))
diag(m)<-0
which(m>0.6,arr.ind=T)
numPCATrain<-preProcess(numericNANTraining,method="pca",thresh=0.80)
numPCATrain
numericTrainingData<-predict(numPCATrain,numericNANTraining)
summary(numericTrainingData)
preProcImpute <- preProcess(method="bagImpute", numericNANTraining)
preProcImpute <- preProcess(numericNANTraining,method="bagImpute")
install.packages("ipred")
library(ipred)
preProcImpute <- preProcess(numericNANTraining,method="bagImpute")
numericNANTrainingImput<- predict(preProcImpute, numericNANTraining)
preProcImpute
numericNANTrainingImput <- predict(preProcImpute, numericNANTraining)
numericNANTraining<- predict(preProcImpute, numericNANTraining)
preProcImpute <- preProcess(method="bagImpute",numericNANTraining)
numericNANTrainingImput<- predict(preProcImpute, numericNANTraining)
preProcImpute <- preProcess(method="knnImpute",numericNANTraining)
numericNANTrainingImput<- predict(preProcImpute, numericNANTraining)
install.packages("RANN")
library(RANN)
numericNANTrainingImput<- predict(preProcImpute, numericNANTraining)
numericNANTrainingImputed<- predict(preProcImpute, numericNANTraining)
numPCATrain<-preProcess(numericNANTrainingImputed,method="pca",thresh=0.80)
numPCATrain
numericTrainingData<-predict(numPCATrain,numericNANTrainingImputed)
summary(numericTrainingData)
head(numericTrainingData)
trainingData<-cbind(numericTrainingData,nzv_training[,non_numericvarsid])
dim(trainingData)
dim(numericTrainingData)
head(trainingData)
trainingData[1:100,]
registerDoMC(cores=4)
install.apckages(domc)
install.apckages("DoMC")
install.apckages("doMC")
install.packages("doMC")
?train
?train
nnetFit <- train(trainingData, trainingData$classe,  method = "nnet", preProcess = "range", tuneLength = 2, trace = FALSE, maxit = 100)
nnetFit <- train(trainingData, trainingData$classe,  method = "knn", preProcess = "range", tuneLength = 2, trace = FALSE, maxit = 100)
nnetFit <- train(trainingData, trainingData$classe,  method = "knn")
nnetFit <- train( trainingData$classe,trainingData,  method = "knn")
warnings()
knnFit2 <- train(trainingData, trainingData$classe,
method = "knn",
preProcess = c("center", "scale","knnImpute"),
tuneLength = 10,
trControl = trainControl(method = "boot"))
knnFit2 <- train(classe ~ ., data= trainingData,
method = "knn",
preProcess = c("center", "scale","knnImpute"),
tuneLength = 10,
trControl = trainControl(method = "boot"))
knnFit2
verification<-verification[,-nzv]
verification <- trainingCSV[-inTrain, ]
trainingCSV = read.csv("pml-training.csv")
inTrain <- createDataPartition(trainingCSV$classe, p=0.75, list=FALSE)
training <- trainingCSV[inTrain, ]
verification <- trainingCSV[-inTrain, ]
verification<-verification[,-nzv]
numericVerification<-verification[,colSums(is.na(numericTraining)) >= 0.4*nrow(numericTraining)]
numericVerification<- predict(preProcImpute, numericVerification)
numericVerification<-verification[,numericvarsid]
numericVerification<-verification[,colSums(is.na(numericTraining)) >= 0.4*nrow(numericTraining)]
numericVerification<- predict(preProcImpute, numericVerification)
numericVerification<-predict(numPCATrain,numericVerification)
verificationData<-cbind(numericVerification,verification[,non_numericvarsid])
confusionMatrix(predict(knnFit2, verificationData[,-verificationData$classe], verification[,verificationData$classe])
)
numericVerification<-verification[,colSums(is.na(numericTraining)) >= 0.4*nrow(numericTraining)]
numericVerification<- predict(preProcImpute, numericVerification)
dim(numericVerification)
dim(numericNANTraining)
numericVerification<-predict(numPCATrain,numericVerification)
knnFit2 <- train(classe ~ ., data= trainingData,method = "knn",preProcess = c("center", "scale","knnImpute","pca"),tuneLength = 10, trControl = trainControl(method = "boot"))
knnFit2
trainingData<-cbind(numericNANTraining,nzv_training[,non_numericvarsid])
verificationData<-cbind(numericVerification,verification[,non_numericvarsid])
knnFit2 <- train(classe ~ ., data= trainingData,method = "knn",preProcess = c("center", "scale","knnImpute","pca"),tuneLength = 10, trControl = trainControl(method = "boot"))
confusionMatrix(predict(knnFit2, verificationData[,-verificationData$classe], verification[,verificationData$classe]))
trainingData<-cbind(numericTrainingData,nzv_training[,non_numericvarsid])
knnFit2 <- train(classe ~ ., data= trainingData,method = "knn",preProcess = c("center", "scale","knnImpute","pca"),tuneLength = 10, trControl = trainControl(method = "boot"))
library(lattice)
library(ggplot2)
library(graphics)
library(Hmisc)
library(e1071)
library(caret)
library(ipred)
library(RANN)
set.seed(1234)
trainingCSV = read.csv("pml-training.csv")
testingCSV =  read.csv("pml-testing.csv")
inTrain <- createDataPartition(trainingCSV$classe, p=0.70, list=FALSE)
training <- trainingCSV[inTrain, ]
validation <- trainingCSV[-inTrain, ]
training<-training[,colSums(is.na(training)) >= 0.4*nrow(training)]
dim(training)
i=0L
for (var in training)  {
i<-i+1
if ((is.na(training[,i])) >= 0.4*nrow(training)) {
}
}
training <- trainingCSV[inTrain, ]
i=0
for (var in training)  {
i<-i+1
if ((is.na(training[,i])) >= 0.4*nrow(training)) {
}
}
warnings()
colSums(is.na(training[,1]))
colSums(is.na(training))
training<-training[,colSums(is.na(training)) >= 0.4*nrow(training)]
dim(training)
validation[,c(names(training))]
validation<-validation[,c(names(training))]
dim(validation)
nzv <- nearZeroVar(training[,-"classe"])
nclos(training)
ncols(training)
ncol(training)
nzv <- nearZeroVar(training[,-ncol(training))
nzv <- nearZeroVar(training[,1:(ncol(training)-1)]
)
dim(nzv)
testing<-testingCSV
testing<-testing[,c(names(training))]
knnFit2 <- train(classe ~ ., data= training,method = "knn",preProcess = c("center", "scale","knnImpute","pca"),tuneLength = 10, trControl = trainControl(method = "boot"))
head(training$classe)
names(training)
trainingCSV = read.csv("pml-training.csv")
testingCSV =  read.csv("pml-testing.csv")
inTrain <- createDataPartition(trainingCSV$classe, p=0.70, list=FALSE)
training <- trainingCSV[inTrain, ]
validation <- trainingCSV[-inTrain, ]
testing<-testingCSV
training<-training[,colSums(is.na(training)) >= 0.4*nrow(training) or ncol(training)]
training<-training[,(colSums(is.na(training)) >= 0.4*nrow(training) or ncol(training))]
ncol(training)
training <- trainingCSV[inTrain, ]
training<-training[,c((colSums(is.na(training[,-160])) >= 0.4*nrow(training)),160)]
dim(training)
head(training$classe)
dim(training)
validation<-validation[,c(names(training))]
dim(training)
testing<-testing[,c(names(training))]
training <- trainingCSV[inTrain, ]
goodVar<-c((colSums(is.na(training[,-160])) >= 0.4*nrow(training)),160)
dim(goodvar)
dim(goodVar)
summary(goodVar)
goodVar
training<-training[,goodVar]
dim(training)
training$classe
validation<-validation[,goodVar]
testing<-testing[,goodVar]
knnFit2 <- train(classe ~ ., data= training,method = "knn",preProcess = c("center", "scale","knnImpute","pca"),tuneLength = 10, trControl = trainControl(method = "boot"))
rf <- train(classe ~ ., data= training,method = "rf",preProcess = c("center", "scale","knnImpute","pca"))
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
rf <- train(classe ~ ., data= training,method = "rf",preProcess = c("center", "scale","knnImpute","pca"))
library(lattice)
library(ggplot2)
library(graphics)
library(Hmisc)
library(e1071)
library(caret)
library(ipred)
library(RANN)
library(randomForest)
set.seed(1234)
trainingCSV = read.csv("pml-training.csv")
testingCSV =  read.csv("pml-testing.csv")
inTrain <- createDataPartition(trainingCSV$classe, p=0.70, list=FALSE)
training <- trainingCSV[inTrain, ]
validation <- trainingCSV[-inTrain, ]
testing<-testingCSV
goodVar<-c((colSums(is.na(training[,-160])) >= 0.4*nrow(training)),160)
training<-training[,goodVar]
dim(training)
validation<-validation[,goodVar]
dim(training)
testing<-testing[,goodVar]
nonNA<-c(!is.na(training[,nrow(training)]))
nonNA<-c(!is.na(training[,training$classe]))
head(nonNA)
training<-training[nonNA,]
dim(training)
training1<-training[complete.cases(training()),]
training1<-training[complete.cases(training),]
head(training1)
dim(training1)
dim(training)
training<-training[complete.cases(training),]
model <- train(classe~.,data=training,method="glm")
library(lattice)
library(ggplot2)
library(Hmisc)
library(e1071)
library(caret)
library(ipred)
library(RANN)
library(randomForest)
set.seed(1234)
rm(list=ls())
trainingCSV = read.csv("pml-training.csv")
inTrain <- createDataPartition(trainingCSV$classe, p=0.60, list=FALSE)
training <- trainingCSV[inTrain, ]
validation <- trainingCSV[-inTrain, ]
goodVar<-c((colSums(is.na(training[,-160])) >= 0.4*nrow(training)),160)
training<-training[,goodVar]
dim(training)
validation<-validation[,goodVar]
dim(training)
training<-training[complete.cases(training),]
dim(training)
model <- train(classe~.,data=training,method="glm")
model <- train(classe~.,data=training,method="glm",preProcess="pca")
model <- train(classe~.,data=training,method="glm",preProcess="knnImpute")
model <- rpart(classe~.,data=training,method="class")
library(rpart)
model <- rpart(classe~.,data=training,method="class")
plotcp(tree)
plotcp(model)
library(rpart)
library(randomForest)
model <- randomForest(classe~.,data=training)
print(model)
head(order(importance(model)))
head(importance(model))
plot(predict(model,newdata=validation[,-validation$classe]),-validation$classe)
plot(predict(model,newdata=validation[,-ncol(validation)]),validation$classe)
confusionMatrix(predict(model,newdata=validation[,-ncol(validation)]),validation$classe)
testing =  read.csv("pml-testing.csv")
predictions<-predict(model,newdata=testing)
dim(testing)
testing<-testing[,goodVar]
dim(testing)
View(testing)
predictions<-predict(model,newdata=testing)
head(predictions)
out<-cbind(testing[,ncol(testing)],prediction)
out<-cbind(testing[,ncol(testing)],predictions)
head(out)
out<-cbind(ProblemID=testing[,ncol(testing)],Prediction=predictions)
out
predictions
out<-cbind(ProblemID=testing[,ncol(testing)],Prediction=predictions[,2])
out
names(predictions)
View(validation)
View(testing)
colnames(predictions) <- c("problem_id","predicted_classe")
colnames(predictions, do.NULL = FALSE)
colnames(predictions) <- c("problem_id","predicted_classe")
dim(predictions)
head(predictions)
colnames(predictions) <- "predicted_classe"
colnames(predictions, do.NULL = FALSE)
accurate<-predict(model,newdata=validation[,-ncol(validation)])==validation$classe
accuracy<-sum(accurate)/count(accurate)
accuracy<-sum(accurate)/nrow(accurate)
accurate
accurate<-if (predict(model,newdata=validation[,-ncol(validation)])==validation$classe) 1 else 0
accuracy<-sum(as.numeri(accurate))/nrow(accurate)
accuracy<-sum(as.numeric(accurate))/nrow(accurate)
accurate
accuracy<-as.numeric(sum(as.numeric(accurate))/nrow(accurate))
accurate
accuracy<-as.numeric(sum(as.numeric(accurate))/nrow(accurate))*100
accurate
accuracy<-as.numeric(sum(as.numeric(accurate))*100/nrow(accurate))
accurate
sum(as.numeric(accurate))
nrow(accurate)
dim(accurate)
accurate
head(accurate)
accurate<-c(predict(model,newdata=validation[,-ncol(validation)])==validation$classe)
head(accurate)
sum(as.numeric(accurate))
nrow(accurate)
dim(accurate)
accurate
accurate<-c(as.numeric(predict(model,newdata=validation[,-ncol(validation)])==validation$classe))
accurate
sum(accurate)
count(accurate)
nrow(accurate)
accuracy<-sum(accurate)*100/nrow(training)
accurate
accuracy<-sum(accurate)*100/nrow(training)
accuracy
sum(accurate)
accuracy<-sum(accurate)*100/nrow(validation)
accuracy
print("Model Accuracy as tested over Validation set = " + accuracy)
print("Model Accuracy as tested over Validation set = "  accuracy)
print("Model Accuracy as tested over Validation set = " , accuracy)
message("Model Accuracy as tested over Validation set = " , accuracy)
sprintf("Model Accuracy as tested over Validation set = %d.2 %" , accuracy)
sprintf("Model Accuracy as tested over Validation set = %d " , accuracy)
message("Model Accuracy as tested over Validation set = " , accuracy, "%")
message("Model Accuracy as tested over Validation set = " , format(round(accuracy, 2), nsmall = 2), "%")
