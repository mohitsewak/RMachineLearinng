{
    "contents" : "Assessment R Markdown\n========================================================\n\n## This is a R markdown for the Assessment (Peer Reviewed) for the Practical Machine Learning Course from the John Hopkinson University\n\n### **Author** - Mohit Sewak - *mohitsewak@gmail.com*\n\n#### Built on R version 2.15.2, using R Studio Version 0.98.507, Posted on GitHub Repository [mohitsewak/RMachineLearning] (http://mohitsewak.github.io/RMachineLearinng/) using gw-pages.\n\n\nLoading required libraries (Results Hidden, Warnings OFF, Messages OFF)\n\n```{r libraries, results='hide',warning=FALSE,message=FALSE}\nlibrary(lattice)\nlibrary(ggplot2)\nlibrary(graphics)\nlibrary(Hmisc)\nlibrary(e1071)\nlibrary(caret)\n\n```\n\nReading (& caching) Files.\n\n```{r reading_files, cache=TRUE}\ntraining = read.csv(\"pml-training.csv\")\ntesting =  read.csv(\"pml-testing.csv\")\n```\n\n\nCreating summary and viewing the top few records, and seeing paired scatter plots in the training file (Results Hidden, Output Cached).\n\n\n```{r data_summary, results=\"hide\", cache=TRUE}\nsummary(training)\nhead(training)\n```\n\nTrying to explore the data, esp the relations between variables. \n\n<p></p>\n\n<p> Since the number of features are huge, so most of the comprehensive plot based visualizations will break.</p>\n\n<p></p>\n\n<p>There we may try to see multiple subsetted plot (as some examples given), or better still, see the tabular correlation matrix of the ones which are highly correlated. We will do these later as for this we will have to segregate the numeric variables and conduct this analysis on those variables alone.</p>\n\n```{r pair_plots, cache=TRUE,fig.width=7, fig.height=6}\nplot(training)\npairs(training[1:10000,1:10])\npairs(training[1:10000,11:20])\npairs(training[1:10000,21:30])\n```\n\nSince most of the columns have no data, or predictive power, it might not be conducive to use them as-is.\n<p> Conducting the following prepocessing operations:</p>\n- Removing Near Zero Value Predictors\n- Principal Component Analysis (PCA) orthogonal rotation to optimize/ reduce dimensions in the data set \n- (Nt: Variable 160 = target variable named \"classe\"\")\n\n```{r preProcess_NZV, cache=TRUE}\nnzv <- nearZeroVar(training[,-160])\ndim(training)\nnzv_training <- training[,-nzv]\ndim(nzv_training)\n```\n\nFinding numric variables, as PCA can be applied only on numeric variables\n\n```{r preProcess_NumericVar, cache=TRUE}\nnumericvars <- NULL\nnumericvarsid <- NULL\n\nnon_numericvars <- NULL\nnon_numericvarsid <- NULL\n\nid<-0L\n\nfor (Var in names(nzv_training)) {\n  \n  id<-id+1\n  \n  if(class(nzv_training[,Var]) == 'integer' | class(nzv_training[,Var]) == 'numeric') {\n    numericvars <- c(numericvars,Var)\n    numericvarsid <- c(numericvarsid,id)\n    }\n  else {\n    non_numericvars <- c(non_numericvars,Var)\n    non_numericvarsid <- c(non_numericvarsid,id)\n    }\n  }\n\nsummary(numericvars)\nnumericvarsid\n```\n\nSeeing the correlation amongst the numeric variables and Conducting PCA on them.\n\n```{r preProcess_PCA, cache=TRUE}\nm<-abs(cor(nzv_training[,numericvarsid]))\ndiag(m)<-0\nwhich(m>0.75,arr.ind=T)\n\nnumPCATrain<-preProcess(nzv_training[,numericvarsid],method=\"pca\",thresh=0.80,na.remove = TRUE)\nnumPCATrain\n\n```\n\n",
    "created" : 1402585280868.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2332422111",
    "id" : "A9E14965",
    "lastKnownWriteTime" : 1402599011,
    "path" : "~/Documents/GitHub/RMachineLearinng/PracticalMachineLearningRMD.Rmd",
    "project_path" : "PracticalMachineLearningRMD.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}