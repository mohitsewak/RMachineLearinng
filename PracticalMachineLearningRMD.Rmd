Assessment R Markdown
========================================================

## This is a R markdown for the Assessment (Peer Reviewed) for the Practical Machine Learning Course from the John Hopkinson University

### **Author** - Mohit Sewak - *mohitsewak@gmail.com*

#### Built on R version 2.15.2, using R Studio Version 0.98.507, Posted on GitHub Repository [mohitsewak/RMachineLearning] (http://mohitsewak.github.io/RMachineLearinng/) using gw-pages.


Loading required libraries (Results Hidden, Warnings OFF, Messages OFF), and setting seed for reproducibility.

```{r libraries, results='hide',warning=FALSE,message=FALSE}
library(lattice)
library(ggplot2)
library(graphics)
library(Hmisc)
library(e1071)
library(caret)
library(ipred)
library(RANN)
set.seed(1234)
```

Reading (& caching) Files, and making training and verification data sets.

```{r reading_files, cache=TRUE}
trainingCSV = read.csv("pml-training.csv")
testingCSV =  read.csv("pml-testing.csv")
inTrain <- createDataPartition(trainingCSV$classe, p=0.75, list=FALSE)
training <- trainingCSV[inTrain, ]
verification <- trainingCSV[-inTrain, ]

```


Creating summary and viewing the top few records, and seeing paired scatter plots in the training file (Results Hidden, Output Cached).


```{r data_summary, results="hide", cache=TRUE}
summary(training)
head(training)
```

Trying to explore the data, esp the relations between variables. 

<p></p>

<p> Since the number of features are huge, so most of the comprehensive plot based visualizations will break.</p>

<p></p>

<p>There we may try to see multiple subsetted plot (as some examples given), or better still, see the tabular correlation matrix of the ones which are highly correlated. We will do these later as for this we will have to segregate the numeric variables and conduct this analysis on those variables alone.</p>

```{r pair_plots, cache=TRUE,fig.width=7, fig.height=6}
plot(training)
pairs(training[1:10000,1:10])
pairs(training[1:10000,11:20])
pairs(training[1:10000,21:30])
```

Since most of the columns have no data, or predictive power, it might not be conducive to use them as-is.
<p> Conducting the following prepocessing operations:</p>
- Removing Near Zero Value Predictors
- Principal Component Analysis (PCA) orthogonal rotation to optimize/ reduce dimensions in the data set 
- (Nt: Variable 160 = target variable named "classe"")

```{r preProcess_NZV, cache=TRUE}
nzv <- nearZeroVar(training[,-160])
dim(training)
nzv_training <- training[,-nzv]
dim(nzv_training)

verification<-verification[,-nzv]
```

Finding numric variables, as PCA can be applied only on numeric variables

```{r preProcess_NumericVar, cache=TRUE}
numericvars <- NULL
numericvarsid <- NULL

non_numericvars <- NULL
non_numericvarsid <- NULL

id<-0L

for (Var in names(nzv_training)) {
  
  id<-id+1
  
  if(class(nzv_training[,Var]) == 'integer' | class(nzv_training[,Var]) == 'numeric') {
    numericvars <- c(numericvars,Var)
    numericvarsid <- c(numericvarsid,id)
    }
  else {
    non_numericvars <- c(non_numericvars,Var)
    non_numericvarsid <- c(non_numericvarsid,id)
    }
  }

summary(numericvars)
numericvarsid
```

Seeing the correlation amongst the numeric variables, with less than 60% null values and Conducting PCA on them after carrying out bag tree imputations for the NA values.

```{r preProcess_PCA, cache=TRUE}
numericTraining<-nzv_training[,numericvarsid]
numericVerification<-verification[,numericvarsid]
numericNANTraining<-numericTraining[,colSums(is.na(numericTraining)) >= 0.4*nrow(numericTraining)]
numericVerification<-verification[,colSums(is.na(numericTraining)) >= 0.4*nrow(numericTraining)]

m<-abs(cor(numericNANTraining))
diag(m)<-0
//which(m>0.75,arr.ind=T)

preProcImpute <- preProcess(numericNANTraining,method="knnImpute")
numericNANTrainingImputed<- predict(preProcImpute, numericNANTraining)
numericVerification<- predict(preProcImpute, numericVerification)

numPCATrain<-preProcess(numericNANTrainingImputed,method="pca",thresh=0.80)
numPCATrain

numericTrainingData<-predict(numPCATrain,numericNANTrainingImputed)
numericVerification<-predict(numPCATrain,numericVerification)
summary(numericTrainingData)
```

Combining the treated numeric data with the categorical predictors and target.

```{r combineData, cache=TRUE}
trainingData<-cbind(numericTrainingData,nzv_training[,non_numericvarsid])
verificationData<-cbind(numericVerification,verification[,non_numericvarsid])
```

Training and applying model.

```{r modeling, cache=TRUE}
knnFit2 <- train(classe ~ ., data= trainingData,method = "knn",preProcess = c("center", "scale","knnImpute","pca"),tuneLength = 10, trControl = trainControl(method = "boot"))

confusionMatrix(predict(knnFit2, verificationData[,-verificationData$classe], verification[,verificationData$classe]))
```


